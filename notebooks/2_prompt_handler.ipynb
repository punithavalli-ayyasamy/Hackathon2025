{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AgriAutoML Prompt Handler\n",
    "\n",
    "This notebook implements the natural language processing interface using Vertex AI PaLM API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "import os\n",
    "import json\n",
    "import logging\n",
    "from typing import Dict, Any, Optional\n",
    "import vertexai\n",
    "from vertexai.language_models import TextGenerationModel\n",
    "from google.oauth2 import service_account\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "class PredictionRequest(BaseModel):\n",
    "    \"\"\"Structure for parsing prediction requests from natural language.\"\"\"\n",
    "    location: str = Field(..., description=\"Location of the farm or field\")\n",
    "    crop_type: str = Field(..., description=\"Type of crop being grown\")\n",
    "    planting_date: str = Field(..., description=\"Date when the crop was planted\")\n",
    "    field_size: float = Field(..., description=\"Size of the field in hectares\")\n",
    "    additional_context: Optional[Dict[str, Any]] = Field(\n",
    "        default={},\n",
    "        description=\"Any additional context provided in the query\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Initialize Vertex AI\n",
    "vertexai.init(\n",
    "    project=os.getenv(\"GCP_PROJECT_ID\"),\n",
    "    location=os.getenv(\"GCP_REGION\"),\n",
    "    credentials=service_account.Credentials.from_service_account_file(\n",
    "        os.getenv(\"GOOGLE_APPLICATION_CREDENTIALS\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Initialize text model\n",
    "model = TextGenerationModel.from_pretrained(\"text-bison-32k\")\n",
    "\n",
    "# Set generation parameters\n",
    "parameters = {\n",
    "    \"temperature\": 0.1,\n",
    "    \"max_output_tokens\": 256,\n",
    "    \"top_k\": 40,\n",
    "    \"top_p\": 0.8\n",
    "}\n",
    "\n",
    "# Create prompt template\n",
    "prompt_template = '''Extract relevant information for crop yield prediction from the following query.\n",
    "Focus on identifying the location, crop type, planting date, and field size.\n",
    "Return the information in JSON format with the following keys:\n",
    "- location: string (e.g., \"Iowa\")\n",
    "- crop_type: string (e.g., \"corn\")\n",
    "- planting_date: string (e.g., \"2025-04-15\")\n",
    "- field_size: number (in hectares)\n",
    "- additional_context: object (any other relevant information)\n",
    "\n",
    "Query: {query}\n",
    "\n",
    "JSON Response:'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "def process_query(query: str) -> Dict[str, Any]:\n",
    "    \"\"\"Process a natural language query and return predictions.\"\"\"\n",
    "    logging.info(f\"Processing query: {query}\")\n",
    "    \n",
    "    # Extract structured information from query\n",
    "    prompt = prompt_template.format(query=query)\n",
    "   \n",
    "    try:\n",
    "        # Make prediction using the model\n",
    "        response = model.predict(\n",
    "            prompt,\n",
    "            **parameters\n",
    "        )\n",
    "        logging.info(f\"Raw API response: {response}\")\n",
    "    except Exception as e:\n",
    "        logging.error(f\"API request failed: {str(e)}\")\n",
    "        raise\n",
    "    \n",
    "    try:\n",
    "        # Extract text from predictions\n",
    "        prediction_text = response.text\n",
    "        logging.info(f\"Extracted prediction text: {prediction_text}\")\n",
    "        \n",
    "        request_data = PredictionRequest(**json.loads(prediction_text))\n",
    "        logging.info(f\"Parsed request data: {request_data}\")\n",
    "        return request_data.dict()\n",
    "    except (json.JSONDecodeError, KeyError, IndexError) as e:\n",
    "        logging.error(f\"Failed to parse model response: {str(e)}\")\n",
    "        raise ValueError(f\"Failed to parse model response: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": [
    "# Test the query processing\n",
    "test_query = \"What's the expected yield for my 5 hectare corn field in Iowa that I planted on April 15th?\"\n",
    "result = process_query(test_query)\n",
    "print(json.dumps(result, indent=2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 }
}
